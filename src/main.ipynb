{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import dependencies.\n",
    "\n",
    "Moduels:\n",
    "    tensorflow: The neural network framework.\n",
    "    layer: The customized single layers.\n",
    "    module: The customized multi-layer modules.\n",
    "    \n",
    "    os: The basic module for path parsing.\n",
    "    json: The basic modue for config parsing.\n",
    "    zipfile: Extract zip file.\n",
    "    random: Shuffle indices.\n",
    "    scipy.io: Load .mat file.\n",
    "    numpy: To process .mat file data.\n",
    "    \n",
    "    tqdm: The 3rd-party looping visualzer.\n",
    "'''\n",
    "\n",
    "import layer, module\n",
    "import tensorflow as tf\n",
    "import os, json, zipfile, random\n",
    "import scipy.io, scipy.misc, numpy as np\n",
    "from enum import Enum\n",
    "from tqdm import tqdm_notebook, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parsing config.\n",
    "\n",
    "The config file is saved to root/config.\n",
    "'''\n",
    "CONFIG_PATH = os.path.abspath('../config.json')\n",
    "with open(CONFIG_PATH) as CONFIG_FILE:\n",
    "    CONFIG = json.loads(CONFIG_FILE.read())\n",
    "    flags = tf.app.flags\n",
    "    flags.DEFINE_string('project', CONFIG['project'], 'The project name.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_pretrained',\n",
    "                        os.path.join(\n",
    "                            os.path.expanduser(CONFIG['pretrained']['path']),\n",
    "                            CONFIG['project']),\n",
    "                        'The path to pretrained parameters.')\n",
    "    flags.DEFINE_boolean('load_pretrained', CONFIG['pretrained']['load'], 'Load the latest pretrained parameters.')\n",
    "    flags.DEFINE_boolean('save_pretrained', CONFIG['pretrained']['save'], 'Save the trained parameters.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_log',\n",
    "                        os.path.join(\n",
    "                            os.path.expanduser(CONFIG['log']['path']),\n",
    "                            CONFIG['project']),\n",
    "                        'The path to log.')\n",
    "    flags.DEFINE_boolean('save_log', CONFIG['log']['save'], 'Save the log.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_data',\n",
    "                        os.path.expanduser(CONFIG['data']['path']),\n",
    "                        'The path to data.')\n",
    "    flags.DEFINE_string('name_of_data', CONFIG['data']['name'], 'The name of data.')\n",
    "    \n",
    "    flags.DEFINE_string('task', CONFIG['task']['step'], 'The task to be done.')\n",
    "    flags.DEFINE_integer('epoch', CONFIG['task']['train']['epoch'], 'The epoch to be trained.')\n",
    "    flags.DEFINE_string('metric', CONFIG['task']['eval']['metric'], 'The evaluation metric.')\n",
    "    flags.DEFINE_float('metric_coefficient', CONFIG['task']['eval']['coefficient'], 'The evaluation metric coefficient.')\n",
    "    \n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Common metadata.\n",
    "'''\n",
    "\n",
    "class DataInterface(object):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def __corrupted(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __reload(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def getBatch(self, batch_size):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "class DataCenter(object):\n",
    "    def __init__(self, data_root):\n",
    "        self.__data_root = data_root\n",
    "    \n",
    "    def request(self, data_name, task):\n",
    "        path = os.path.join(self.__data_root, data_name)\n",
    "        \n",
    "        if data_name == 'FLIC':\n",
    "            return FLIC(data_path = path, task = task)\n",
    "        elif data_name == 'MPII':\n",
    "            return MPII(data_path = path, task = task)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "class Joint(Enum):\n",
    "\n",
    "    # FLIC\n",
    "    L_Shoulder  =   1\n",
    "    R_Shoulder  =   2\n",
    "    L_Elbow     =   3\n",
    "    R_Elbow     =   4\n",
    "    L_Wrist     =   5\n",
    "    R_Wrist     =   6\n",
    "    L_Hip       =   7\n",
    "    R_Hip       =   8\n",
    "    L_Knee      =   9\n",
    "    R_Knee      =   10\n",
    "    L_Ankle     =   11\n",
    "    R_Ankle     =   12\n",
    "\n",
    "    L_Eye       =   13\n",
    "    R_Eye       =   14\n",
    "    L_Ear       =   15\n",
    "    R_Ear       =   16\n",
    "    M_Nose      =   17\n",
    "\n",
    "    M_Shoulder  =   18\n",
    "    M_Hip       =   19\n",
    "    M_Ear       =   20\n",
    "    M_Torso     =   21\n",
    "    M_LUpperArm =   22\n",
    "    M_RUpperArm =   23\n",
    "    M_LLowerArm =   24\n",
    "    M_RLowerArm =   25\n",
    "    M_LUpperLeg =   26\n",
    "    M_RUpperLeg =   27\n",
    "    M_LLowerLeg =   28\n",
    "    M_RLowerLeg =   29\n",
    "\n",
    "    # MPII\n",
    "    # M_Pelvis    =   M_Hip\n",
    "    # M_Thorax    =   M_Torso\n",
    "    M_UpperNeck =   30\n",
    "    M_HeadTOP   =   31\n",
    "    \n",
    "class Basis(Enum):\n",
    "    x = 0\n",
    "    y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FLIC data reader\n",
    "'''       \n",
    "class FLIC(DataInterface):\n",
    "    \n",
    "    archive_file = 'FLIC.zip'\n",
    "    extract_dir = 'FLIC'\n",
    "    matlab_file = 'examples.mat'\n",
    "    index_file = { 'train': 'train.txt', 'eval': 'eval.txt' }\n",
    "    number_of_data = 5003\n",
    "    train_ratio = 0.9\n",
    "    eval_ratio = 1.0 - train_ratio\n",
    "    \n",
    "    joint2index = {\n",
    "        Joint.L_Shoulder: 0,\n",
    "        Joint.L_Elbow: 1,\n",
    "        Joint.L_Wrist: 2,\n",
    "        Joint.R_Shoulder: 3,\n",
    "        Joint.R_Elbow: 4,\n",
    "        Joint.R_Wrist: 5,\n",
    "        Joint.L_Hip: 6,\n",
    "        Joint.R_Hip: 9,\n",
    "        Joint.L_Eye: 12,\n",
    "        Joint.R_Eye: 13,\n",
    "        Joint.M_Nose: 16\n",
    "    }\n",
    "    \n",
    "    def __init__(self, data_path, task):\n",
    "        self.__data_path = data_path\n",
    "        \n",
    "        if self.__corrupted():\n",
    "            self.__reload()\n",
    "            \n",
    "        extract_path = os.path.join(self.__data_path, FLIC.extract_dir)\n",
    "        matlab_path = os.path.join(extract_path, FLIC.matlab_file)\n",
    "        self.__FLIC = scipy.io.loadmat(matlab_path)\n",
    "        self.__index = { 'train': open(os.path.join(self.__data_path, FLIC.index_file['train']), 'r'),\n",
    "                     'eval': open(os.path.join(self.__data_path, FLIC.index_file['eval']), 'r')}\n",
    "        self.__task = task\n",
    "        \n",
    "    def __delete__(self):\n",
    "        self.__index['train'].close()\n",
    "        self.__index['eval'].close()\n",
    "    \n",
    "    def __corrupted(self):\n",
    "        archive_path = os.path.join(self.__data_path, FLIC.archive_file)\n",
    "        print('Check if the archive file exists...', end = '')\n",
    "        if not os.path.exists(archive_path):\n",
    "            raise Exception('You have to download the archive file from https://bensapp.github.io/flic-dataset.html')\n",
    "        print('success!')\n",
    "        print('\\tpath:', archive_path)\n",
    "        \n",
    "        \n",
    "        extract_path = os.path.join(self.__data_path, FLIC.extract_dir)\n",
    "        print('Check if the archive file is extracted...', end = '')\n",
    "        if not os.path.exists(extract_path):\n",
    "            print('failed!')\n",
    "            return True\n",
    "        print('success!')\n",
    "        print('\\tpath:', extract_path)\n",
    "        \n",
    "        \n",
    "        index_path = { 'train': os.path.join(self.__data_path, FLIC.index_file['train']),\n",
    "                     'eval': os.path.join(self.__data_path, FLIC.index_file['eval'])}\n",
    "        print('Check if the index file is exists...', end = '')\n",
    "        if not (os.path.exists(index_path['train']) and os.path.exists(index_path['eval'])):\n",
    "            print('failed!')\n",
    "            return True\n",
    "        print('success!')\n",
    "        print('\\ttrain path:', index_path['train'])\n",
    "        print('\\teval path:', index_path['eval'])\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    def __reload(self):\n",
    "        archive_path = os.path.join(self.__data_path, FLIC.archive_file)\n",
    "        print('Extract the archive file...', end = '')\n",
    "        with zipfile.ZipFile(archive_path, 'r') as archive_ref:\n",
    "            archive_ref.extractall(self.__data_path)\n",
    "        print('success!')\n",
    "        extract_path = os.path.join(self.__data_path, FLIC.extract_dir)\n",
    "        print('\\tpath:', extract_path)\n",
    "        \n",
    "        \n",
    "        index_path = { 'train': os.path.join(self.__data_path, FLIC.index_file['train']),\n",
    "                     'eval': os.path.join(self.__data_path, FLIC.index_file['eval'])}\n",
    "        index_list = [i for i in range(FLIC.number_of_data)]\n",
    "        random.shuffle(index_list)\n",
    "        print('Generate the random train/eval set...', end = '')\n",
    "        with open(index_path['train'], 'w') as train_index_file:\n",
    "            for i in range(int(FLIC.train_ratio * FLIC.number_of_data)):\n",
    "                train_index_file.write(str(index_list[i]) + '\\n')\n",
    "                \n",
    "        with open(index_path['eval'], 'w') as train_index_file:\n",
    "            for i in range(int(FLIC.train_ratio * FLIC.number_of_data), FLIC.number_of_data):\n",
    "                train_index_file.write(str(index_list[i]) + '\\n')\n",
    "        print('success!')\n",
    "        print('\\ttrain path:', index_path['train'])\n",
    "        print('\\teval path:', index_path['eval'])\n",
    "        \n",
    "    def getBatch(self, batch_size):\n",
    "        return self.__getMasking()\n",
    "        '''\n",
    "        return [(lambda index: (\n",
    "            self.__getImage(index),\n",
    "            self.__getMasking(index)\n",
    "        ))(self.__getNext()) for i in range(batch_size)]\n",
    "        '''\n",
    "            \n",
    "    def __getNext(self):\n",
    "        index = self.__index[self.__task].readline()\n",
    "        if index == '':\n",
    "            self.__index[self.__task].seek(0)\n",
    "            index = self.__index[self.__task].readline()\n",
    "        return int(index)\n",
    "            \n",
    "    def __getImage(self, index):\n",
    "        img_path = np.squeeze(np.squeeze(self.__FLIC['examples']['filepath'])[index])\n",
    "        img_dims = np.squeeze(np.squeeze(self.__FLIC['examples']['imgdims'])[index])\n",
    "        return img_path\n",
    "    \n",
    "    def __getKeypoints(self, index):\n",
    "        keypoints_ref = np.squeeze(np.squeeze(np.squeeze(self.__FLIC['examples'])[index])['coords'])\n",
    "        for joint in Joint:\n",
    "            if joint not in FLIC.joint2index:\n",
    "                x = float('nan')\n",
    "                y = float('nan')\n",
    "            else:\n",
    "                x = keypoints_ref[Basis.x.value][FLIC.joint2index[joint]]\n",
    "                y = keypoints_ref[Basis.y.value][FLIC.joint2index[joint]]\n",
    "            print(joint, x, y)\n",
    "    \n",
    "    def __getMasking(self):\n",
    "        return [(lambda joint: joint in FLIC.joint2index)(joint) for joint in Joint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' MPII data reader\n",
    "'''\n",
    "        \n",
    "class MPII(DataInterface):\n",
    "    def __init__(self, data_path, task):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __corrupted(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __reload(self):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if the archive file exists...success!\n",
      "\tpath: /home/nulledge/Workspace/data/FLIC/FLIC.zip\n",
      "Check if the archive file is extracted...success!\n",
      "\tpath: /home/nulledge/Workspace/data/FLIC/FLIC\n",
      "Check if the index file is exists...success!\n",
      "\ttrain path: /home/nulledge/Workspace/data/FLIC/train.txt\n",
      "\teval path: /home/nulledge/Workspace/data/FLIC/eval.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = DataCenter(data_root = FLAGS.path_to_data).request(data_name = FLAGS.name_of_data, task = FLAGS.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, False, False, False, False, True, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "batch = dataset.getBatch(batch_size = 1)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('input'):\n",
    "    images = tf.placeholder(\n",
    "        name = 'image',\n",
    "        dtype = tf.float32,\n",
    "        shape = [None, metadata.image.height, metadata.image.width, metadata.image.channel])\n",
    "    heatmaps_groundtruth = tf.placeholder(\n",
    "        name = 'heatmap_groundtruth',\n",
    "        dtype = tf.float32,\n",
    "        shape = [None, metadata.heatmap.height, metadata.heatmap.width, metadata.joint])\n",
    "    train = tf.placeholder(\n",
    "        name = 'train',\n",
    "        dtype = tf.bool,\n",
    "        shape = ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size 256 * 256 * 3\n",
    "\n",
    "with tf.variable_scope('compress'):\n",
    "    with tf.variable_scope('conv_bn_relu'):\n",
    "        net = layer.conv(input = images, ksize = 7, kchannel = 64, kstride = 2) # 128 * 128 * 64\n",
    "        net = layer.bn(input = net, train = train)\n",
    "        net = layer.relu(input = net)\n",
    "\n",
    "    net = module.bottleneck(input = net, kchannel = 128, train = train, name = 'A') # 128 * 128 * 128\n",
    "    net = layer.pool(input = net) # 64 * 64 * 128\n",
    "    net = module.bottleneck(input = net, kchannel = 128, train = train, name = 'B') # 64 * 64 * 128\n",
    "    net = module.bottleneck(input = net, kchannel = 256, train = train, name = 'C') # 64 * 64 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tf_Spectrum:\n",
    "    Color = tf.constant([\n",
    "        [128, 0, 0],\n",
    "        [255, 0, 0],\n",
    "        [0, 255, 0],\n",
    "        [0, 255, 255],\n",
    "        [0, 0, 255]\n",
    "    ], dtype = tf.float64)\n",
    "\n",
    "def tf_gray2color(gray, spectrum = tf_Spectrum.Color):\n",
    "    indices = tf.floor_div(gray, 64)\n",
    "    \n",
    "    t = (gray - indices * 64) / (64)\n",
    "    t = tf.stack([t]*3, 2)\n",
    "    indices = tf.cast(indices, dtype = tf.int32)\n",
    "    \n",
    "    return (1-t)*tf.gather(spectrum, indices) + t*tf.gather(spectrum, indices+1)\n",
    "\n",
    "def tf_merge(image, heatmaps):\n",
    "    board = tf.zeros(\n",
    "        shape = (\n",
    "            metadata.heatmap.height,\n",
    "            metadata.heatmap.width,\n",
    "            metadata.image.channel\n",
    "        ), dtype = tf.float64)\n",
    "    for joint in range(metadata.joint):\n",
    "        board = tf.maximum(\n",
    "            board, \n",
    "            tf_gray2color(tf.cast(heatmaps[:, :, joint], dtype=tf.float64)))\n",
    "    board = tf.image.resize_images(\n",
    "        board, \n",
    "        [metadata.image.height, metadata.image.width])\n",
    "    image = tf.cast(image, dtype = tf.float32)\n",
    "    return tf.cast(tf.add(tf.multiply(board, 0.6), tf.multiply(image, 0.4)), dtype = tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_stage = 8\n",
    "heatmaps = []\n",
    "\n",
    "for stage in range(1, last_stage+1):\n",
    "    with tf.variable_scope('hourglass_' + str(stage)):\n",
    "        prev = tf.identity(net)\n",
    "        net = module.hourglass(input = net, train = train) # 64 * 64 * 256\n",
    "\n",
    "        with tf.variable_scope('inter_hourglasses'):\n",
    "            net = module.bottleneck(input = net, train = train) # 64 * 64 * 256\n",
    "            net = layer.conv(input = net, ksize = 1, kchannel = 256) # 64 * 64 * 256\n",
    "            net = layer.bn(input = net, train = train)\n",
    "            net = layer.relu(input = net)\n",
    "\n",
    "        with tf.variable_scope('heatmap'):\n",
    "            heatmap = layer.conv(input = net, ksize = 1, kchannel = metadata.joint) # 64 * 64 * joint\n",
    "            heatmaps.append(heatmap)\n",
    "\n",
    "        if stage != last_stage:\n",
    "            net = layer.conv(input = net, ksize = 1, kchannel = 256, name = 'inter')\\\n",
    "                + layer.conv(input = heatmap, ksize = 1, kchannel = 256, name = 'heatmap')\\\n",
    "                + prev # 64 * 64 * 256\n",
    "\n",
    "merged = tf_merge(images[0], heatmaps[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAGS.train :\n",
    "    with tf.variable_scope('loss'):\n",
    "        loss = tf.losses.mean_squared_error(heatmaps_groundtruth, heatmaps[0])\n",
    "        for stage in range(1, last_stage):\n",
    "            loss = loss + tf.losses.mean_squared_error(heatmaps_groundtruth, heatmaps[stage])\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.AdamOptimizer(name = 'optimizer', learning_rate = 0.00025).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "reader = Reader(train = os.path.expanduser('~/Temp/train19122.dat'),\n",
    "                test = os.path.expanduser('~/Temp/test2125.dat'))\n",
    "if FLAGS.train:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, FLAGS.ckpt)\n",
    "else:\n",
    "    saver.restore(sess, FLAGS.ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAGS.train == True:\n",
    "    for epoch in range(100):\n",
    "        train_iter = tqdm_notebook(total = 19122, desc = 'epoch: ' + str(epoch) + '/100')\n",
    "        for i in range(3187):\n",
    "            train_images, train_heatmaps = reader.batch(size = FLAGS.batch, is_train = True)\n",
    "            _, result = sess.run([optimizer, loss],\n",
    "                feed_dict = {\n",
    "                    images: train_images,\n",
    "                    heatmaps_groundtruth: train_heatmaps,\n",
    "                    train: True})\n",
    "            train_iter.set_postfix(loss = result)\n",
    "            train_iter.update(FLAGS.batch)\n",
    "        train_iter.close();\n",
    "        temp = saver.save(sess, FLAGS.ckpt)\n",
    "    '''\n",
    "    for epoch in tqdm_notebook(tqdm(range(10), desc = 'epoch')):\n",
    "        inner_iter = tqdm_notebook(tqdm(range(563), desc = 'iter'), leave = False)\n",
    "        for iterator in inner_iter:\n",
    "            train_images, train_heatmaps = reader.batch(size = flag.batch_size, is_train = True)\n",
    "            _, result = sess.run([optimizer, loss],\n",
    "                feed_dict = {\n",
    "                    images: train_images,\n",
    "                    heatmaps_groundtruth: train_heatmaps,\n",
    "                    train: True})\n",
    "            wrap = lambda label, value: label + '(' + str(value) + ')'\n",
    "            inner_iter.set_postfix(loss = result)\n",
    "        temp = saver.save(sess, os.path.join(ckpt_path, 'hourglass_' + str(start_epoch + epoch + 1) + '.ckpt'))\n",
    "        print(\"Model saved in file: %s\" % temp)\n",
    "        '''\n",
    "else:\n",
    "    heatmap_idx = 0\n",
    "    total_result = []\n",
    "    test_iter = tqdm_notebook(total = 2125, desc = 'test')\n",
    "    for i in range(2125 // 5):\n",
    "        test_images, test_heatmaps = reader.batch(size = 5, is_train = False)\n",
    "        result, output_heatmap = sess.run([loss, merged],\n",
    "            feed_dict = {\n",
    "                images: test_images,\n",
    "                heatmaps_groundtruth: test_heatmaps,\n",
    "                train: False})\n",
    "        test_iter.update(5)\n",
    "        total_result.append(result)\n",
    "        cv2.imwrite('merged' + str(heatmap_idx) + '.jpg', output_heatmap)\n",
    "        heatmap_idx += 1\n",
    "    test_iter.close();\n",
    "    print(sum(total_result)/(2125//5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_idx = 0\n",
    "total_result = []\n",
    "test_iter = tqdm_notebook(total = 2125, desc = 'test')\n",
    "for i in range(2125 // 5):\n",
    "    test_images, test_heatmaps = reader.batch(size = 5, is_train = False)\n",
    "    result, output_heatmap = sess.run([loss, merged],\n",
    "        feed_dict = {\n",
    "            images: test_images,\n",
    "            heatmaps_groundtruth: test_heatmaps,\n",
    "            train: False})\n",
    "    test_iter.update(5)\n",
    "    total_result.append(result)\n",
    "    cv2.imwrite('merged' + str(heatmap_idx) + '.jpg', output_heatmap)\n",
    "    heatmap_idx += 1\n",
    "test_iter.close();\n",
    "print(sum(total_result)/(2125//5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
