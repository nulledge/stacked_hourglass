{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nulledge/Environments/tf-36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "''' Import dependencies.\n",
    "\n",
    "Moduels:\n",
    "    tensorflow: The neural network framework.\n",
    "    layer: The customized single layers.\n",
    "    module: The customized multi-layer modules.\n",
    "    \n",
    "    os: The basic module for path parsing.\n",
    "    json: The basic modue for config parsing.\n",
    "    zipfile: Extract zip file.\n",
    "    random: Shuffle indices.\n",
    "    scipy.io: Load .mat file.\n",
    "    numpy: To process .mat file data.\n",
    "    \n",
    "    tqdm: The 3rd-party looping visualzer.\n",
    "'''\n",
    "\n",
    "import layer, module\n",
    "import tensorflow as tf\n",
    "import os, json, zipfile, random, datetime, glob\n",
    "import scipy.io, scipy.misc, imageio, math, numpy as np\n",
    "from enum import Enum\n",
    "from tqdm import tqdm, trange\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parsing config.\n",
    "\n",
    "The config file is saved to root/config.\n",
    "'''\n",
    "CONFIG_PATH = os.path.abspath('../config.json')\n",
    "with open(CONFIG_PATH) as CONFIG_FILE:\n",
    "    CONFIG = json.loads(CONFIG_FILE.read())\n",
    "    flags = tf.app.flags\n",
    "    flags.DEFINE_string('project', CONFIG['project'], 'The project name.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_pretrained',\n",
    "                        os.path.join(\n",
    "                            os.path.expanduser(CONFIG['pretrained']['path']),\n",
    "                            CONFIG['project']),\n",
    "                        'The path to pretrained parameters.')\n",
    "    flags.DEFINE_boolean('load_pretrained', CONFIG['pretrained']['load'], 'Load the latest pretrained parameters.')\n",
    "    flags.DEFINE_boolean('save_pretrained', CONFIG['pretrained']['save'], 'Save the trained parameters.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_log',\n",
    "                        os.path.join(\n",
    "                            os.path.expanduser(CONFIG['log']['path']),\n",
    "                            CONFIG['project']),\n",
    "                        'The path to log.')\n",
    "    flags.DEFINE_boolean('save_log', CONFIG['log']['save'], 'Save the log.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_data',\n",
    "                        os.path.expanduser(CONFIG['data']['path']),\n",
    "                        'The path to data.')\n",
    "    flags.DEFINE_string('name_of_data', CONFIG['data']['name'], 'The name of data.')\n",
    "    \n",
    "    flags.DEFINE_string('task', CONFIG['task']['step'], 'The task to be done.')\n",
    "    flags.DEFINE_integer('epoch', CONFIG['task']['train']['epoch'], 'The epoch to be trained.')\n",
    "    flags.DEFINE_string('metric', CONFIG['task']['eval']['metric'], 'The evaluation metric.')\n",
    "    flags.DEFINE_float('metric_coefficient', CONFIG['task']['eval']['coefficient'], 'The evaluation metric coefficient.')\n",
    "    \n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('input'):\n",
    "    images = tf.placeholder(\n",
    "        name = 'image',\n",
    "        dtype = tf.float32,\n",
    "        shape = [None, 256, 256, 3])\n",
    "    heatmaps_groundtruth = tf.placeholder(\n",
    "        name = 'heatmap_groundtruth',\n",
    "        dtype = tf.float32,\n",
    "        shape = [None, 64, 64, len(Joint)])\n",
    "    train = tf.placeholder(\n",
    "        name = 'train',\n",
    "        dtype = tf.bool,\n",
    "        shape = ())\n",
    "    mask = tf.placeholder(\n",
    "        name = 'mask',\n",
    "        dtype = tf.float32,\n",
    "        shape = [len(Joint)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size 256 * 256 * 3\n",
    "\n",
    "with tf.variable_scope('compress'):\n",
    "    with tf.variable_scope('conv_bn_relu'):\n",
    "        net = layer.conv(input = images, ksize = 7, kchannel = 64, kstride = 2) # 128 * 128 * 64\n",
    "        net = layer.bn(input = net, train = train)\n",
    "        net = layer.relu(input = net)\n",
    "\n",
    "    net = module.bottleneck(input = net, kchannel = 128, train = train, name = 'A') # 128 * 128 * 128\n",
    "    net = layer.pool(input = net) # 64 * 64 * 128\n",
    "    net = module.bottleneck(input = net, kchannel = 128, train = train, name = 'B') # 64 * 64 * 128\n",
    "    net = module.bottleneck(input = net, kchannel = 256, train = train, name = 'C') # 64 * 64 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tf_Spectrum:\n",
    "    Color = tf.constant([\n",
    "        [0, 0, 128],\n",
    "        [0, 0, 255],\n",
    "        [0, 255, 0],\n",
    "        [255, 255, 0],\n",
    "        [255, 0, 0]\n",
    "    ], dtype = tf.float32)\n",
    "\n",
    "def tf_gray2color(gray, spectrum = tf_Spectrum.Color):\n",
    "    indices = tf.floor_div(gray, 64)\n",
    "    \n",
    "    t = tf.expand_dims((gray - indices * 64) / (64), axis = -1)\n",
    "    indices = tf.cast(indices, dtype = tf.int32)\n",
    "    \n",
    "    return tf.add(\n",
    "        tf.multiply(tf.gather(spectrum, indices), 1 - t),\n",
    "        tf.multiply(tf.gather(spectrum, indices+1), t)\n",
    "    )\n",
    "\n",
    "def tf_merge(rgb, heat):\n",
    "    heat = tf.image.resize_images(\n",
    "        heat,\n",
    "        [256, 256]\n",
    "    )\n",
    "    heat = tf.reduce_max(\n",
    "        heat,\n",
    "        axis = -1\n",
    "    )\n",
    "    return tf.cast(\n",
    "        tf.add(\n",
    "            tf.multiply(\n",
    "                tf_gray2color(heat),\n",
    "                0.6\n",
    "            ),\n",
    "            tf.multiply(rgb, 0.4)\n",
    "        ),\n",
    "        dtype = tf.uint8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_stage = 8\n",
    "heatmaps = []\n",
    "if FLAGS.task == 'eval':\n",
    "    output = []\n",
    "\n",
    "for stage in range(1, last_stage+1):\n",
    "    with tf.variable_scope('hourglass_' + str(stage)):\n",
    "        prev = tf.identity(net)\n",
    "        net = module.hourglass(input = net, train = train) # 64 * 64 * 256\n",
    "\n",
    "        with tf.variable_scope('inter_hourglasses'):\n",
    "            net = module.bottleneck(input = net, train = train) # 64 * 64 * 256\n",
    "            net = layer.conv(input = net, ksize = 1, kchannel = 256) # 64 * 64 * 256\n",
    "            net = layer.bn(input = net, train = train)\n",
    "            net = layer.relu(input = net)\n",
    "\n",
    "        with tf.variable_scope('heatmap'):\n",
    "            heatmap = layer.conv(input = net, ksize = 1, kchannel = len(Joint)) # 64 * 64 * joint\n",
    "            \n",
    "            heatmaps.append(heatmap)\n",
    "            if FLAGS.task == 'eval':\n",
    "                output.append(tf_merge(images, heatmap))\n",
    "\n",
    "        if stage != last_stage:\n",
    "            net = layer.conv(input = net, ksize = 1, kchannel = 256, name = 'inter')\\\n",
    "                + layer.conv(input = heatmap, ksize = 1, kchannel = 256, name = 'heatmap')\\\n",
    "                + prev # 64 * 64 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAGS.task == 'train' :\n",
    "    with tf.variable_scope('loss'):\n",
    "        loss = tf.losses.mean_squared_error(heatmaps_groundtruth, heatmaps[0] * mask)\n",
    "        for stage in range(1, last_stage):\n",
    "            loss = loss + tf.losses.mean_squared_error(heatmaps_groundtruth, heatmaps[stage] * mask)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.AdamOptimizer(name = 'optimizer', learning_rate = 0.00025).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if the archive file is extracted...success!\n",
      "\timage path: /home/nulledge/Datasets/MPII/images\n",
      "\tannotation path: /home/nulledge/Datasets/MPII/mpii_human_pose_v1_u12_2\n",
      "Load the annotation file...success!\n",
      "Check if the index file is exists...success!\n",
      "\ttrain path: /home/nulledge/Datasets/MPII/train.txt\n",
      "\teval path: /home/nulledge/Datasets/MPII/eval.txt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "reader = DataCenter(root = FLAGS.path_to_data).request(data = FLAGS.name_of_data, task = FLAGS.task)\n",
    "\n",
    "if FLAGS.load_pretrained:\n",
    "    list_of_files = glob.glob(os.path.join(FLAGS.path_to_pretrained, '*'))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    file_name = os.path.basename(latest_file).split('.ckpt')[0]\n",
    "    saver.restore(sess, os.path.join(FLAGS.path_to_pretrained, file_name + '.ckpt'))\n",
    "else:\n",
    "    file_name = 'None'\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/20:   0%|          | 0/17266 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:201: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:239: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:240: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "epoch: 1/20:   0%|          | 40/17266 [00:39<5:30:01,  1.15s/it, loss=98.7]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:241: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "epoch: 1/20: 100%|██████████| 17266/17266 [32:51<00:00,  5.49it/s, loss=65.3]\n",
      "epoch: 2/20:  23%|██▎       | 3944/17266 [07:22<23:12,  9.57it/s, loss=84.3]"
     ]
    }
   ],
   "source": [
    "if FLAGS.task == 'train':\n",
    "    for epoch in range(1, FLAGS.epoch + 1):\n",
    "        if FLAGS.name_of_data == 'FLIC':\n",
    "            one_epoch = int(FLIC.NUMBER_OF_DATA * FLIC.TRAIN_RATIO)\n",
    "        elif FLAGS.name_of_data == 'MPII':\n",
    "            one_epoch = int((17266 + 1919) * MPII.TRAIN_RATIO)\n",
    "        train_iter = tqdm(total = one_epoch, desc = 'epoch: ' + str(epoch) + '/' + str(FLAGS.epoch))\n",
    "        reader.resetBatch()\n",
    "        for i in range(one_epoch):\n",
    "            train_images, train_heatmaps, _, train_mask = reader.getBatch(8)\n",
    "            if train_images.shape[0] == 0:\n",
    "                break\n",
    "            _, result = sess.run([optimizer, loss],\n",
    "                feed_dict = {\n",
    "                    images: train_images,\n",
    "                    heatmaps_groundtruth: train_heatmaps,\n",
    "                    train: True,\n",
    "                    mask: train_mask\n",
    "                })\n",
    "            train_iter.set_postfix(loss = result)\n",
    "            train_iter.update(train_images.shape[0])\n",
    "        train_iter.close();\n",
    "        \n",
    "        if FLAGS.save_pretrained:\n",
    "            temp = saver.save(sess, os.path.join(FLAGS.path_to_pretrained, str(datetime.datetime.now()) + '_epoch' + str(epoch) + '.ckpt'))\n",
    "else:\n",
    "    if FLAGS.name_of_data == 'FLIC':\n",
    "        one_epoch = FLIC.NUMBER_OF_DATA - int(FLIC.NUMBER_OF_DATA * FLIC.TRAIN_RATIO)\n",
    "    elif FLAGS.name_of_data == 'MPII':\n",
    "        one_epoch = (17266 + 1919) - int((17266 + 1919) * MPII.TRAIN_RATIO)\n",
    "        \n",
    "    reader.resetBatch()\n",
    "    eval_iter = tqdm(total = one_epoch, desc = 'ckpt: ' + file_name)\n",
    "    cnt = [0] * len(Joint)\n",
    "    for i in range(one_epoch):\n",
    "        eval_images, eval_heatmaps, eval_extra, eval_mask = reader.getBatch(8)\n",
    "        if eval_images.shape[0] == 0:\n",
    "            break\n",
    "        to_cal, result = sess.run([heatmaps, output],\n",
    "            feed_dict = {\n",
    "                images: eval_images,\n",
    "                heatmaps_groundtruth: eval_heatmaps,\n",
    "                train: False})\n",
    "        eval_iter.update(eval_images.shape[0])\n",
    "        \n",
    "        for batch in range(eval_images.shape[0]):\n",
    "            for joint in Joint:\n",
    "                if FLAGS.name_of_data == 'FLIC' and joint in FLIC.joint2index:\n",
    "                    maximum = -1.0\n",
    "                    px = -1\n",
    "                    py = -1\n",
    "                    for y in range(64):\n",
    "                        for x in range(64):\n",
    "                            if to_cal[-1][batch][y, x, joint.value - 1] > maximum:\n",
    "                                maximum = to_cal[-1][batch][y, x, joint.value - 1]\n",
    "                                py = y\n",
    "                                px = x\n",
    "                    dist = np.linalg.norm(\n",
    "                        np.array([py, px])\n",
    "                        - np.array(eval_extra[batch][0][joint.value - 1]))\n",
    "                    if dist <= eval_extra[batch][1] * FLAGS.metric_coefficient:\n",
    "                        cnt[joint.value - 1] += 1\n",
    "                elif FLAGS.name_of_data == 'MPII' and joint in MPII.joint2index:\n",
    "                    pass\n",
    "            # imageio.imwrite('img/result' + str(i) + '_' + str(batch) + '_' + str(cnt) + '_' + str(len(FLIC.joint2index)) + '.png', result[-1][batch])\n",
    "    for joint in Joint:\n",
    "        if joint not in FLIC.joint2index:\n",
    "            continue\n",
    "        print(joint, cnt[joint.value - 1] / one_epoch)\n",
    "                \n",
    "            \n",
    "    eval_iter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reader.resetBatch()\n",
    "_, heat, _, _ = reader.getBatch(1)\n",
    "heat = heat[0]\n",
    "maximum = -1\n",
    "for y in range(64):\n",
    "    for x in range(64):\n",
    "        heat[y, x, 0] = max(heat[y, x, :])\n",
    "        if heat[y, x, 0] > maximum:\n",
    "            maximum = heat[y, x, 0]\n",
    "imageio.imwrite('img/heat.jpg', heat[:, :, 0])\n",
    "print(maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
