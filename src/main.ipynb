{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nulledge/Environments/tf-36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "''' Import dependencies.\n",
    "\n",
    "Moduels:\n",
    "    tensorflow: The neural network framework.\n",
    "    layer: The customized single layers.\n",
    "    module: The customized multi-layer modules.\n",
    "    \n",
    "    os: The basic module for path parsing.\n",
    "    json: The basic modue for config parsing.\n",
    "    zipfile: Extract zip file.\n",
    "    random: Shuffle indices.\n",
    "    scipy.io: Load .mat file.\n",
    "    numpy: To process .mat file data.\n",
    "    \n",
    "    tqdm: The 3rd-party looping visualzer.\n",
    "'''\n",
    "\n",
    "import layer, module\n",
    "import tensorflow as tf\n",
    "import os, json, datetime, glob\n",
    "import imageio, numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parsing config.\n",
    "\n",
    "The config file is saved to root/config.\n",
    "'''\n",
    "CONFIG_PATH = os.path.abspath('../config.json')\n",
    "with open(CONFIG_PATH) as CONFIG_FILE:\n",
    "    CONFIG = json.loads(CONFIG_FILE.read())\n",
    "    flags = tf.app.flags\n",
    "    flags.DEFINE_string('project', CONFIG['project'], 'The project name.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_pretrained',\n",
    "                        os.path.join(\n",
    "                            os.path.expanduser(CONFIG['pretrained']['path']),\n",
    "                            CONFIG['project']),\n",
    "                        'The path to pretrained parameters.')\n",
    "    flags.DEFINE_boolean('load_pretrained', CONFIG['pretrained']['load'], 'Load the latest pretrained parameters.')\n",
    "    flags.DEFINE_boolean('save_pretrained', CONFIG['pretrained']['save'], 'Save the trained parameters.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_log',\n",
    "                        os.path.join(\n",
    "                            os.path.expanduser(CONFIG['log']['path']),\n",
    "                            CONFIG['project']),\n",
    "                        'The path to log.')\n",
    "    flags.DEFINE_boolean('save_log', CONFIG['log']['save'], 'Save the log.')\n",
    "    \n",
    "    flags.DEFINE_string('path_to_data',\n",
    "                        os.path.expanduser(CONFIG['data']['path']),\n",
    "                        'The path to data.')\n",
    "    flags.DEFINE_string('name_of_data', CONFIG['data']['name'], 'The name of data.')\n",
    "    \n",
    "    flags.DEFINE_string('task', CONFIG['task']['step'], 'The task to be done.')\n",
    "    flags.DEFINE_integer('epoch', CONFIG['task']['train']['epoch'], 'The epoch to be trained.')\n",
    "    flags.DEFINE_string('metric', CONFIG['task']['eval']['metric'], 'The evaluation metric.')\n",
    "    flags.DEFINE_float('metric_coefficient', CONFIG['task']['eval']['coefficient'], 'The evaluation metric coefficient.')\n",
    "    \n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('input'):\n",
    "    images = tf.placeholder(\n",
    "        name = 'image',\n",
    "        dtype = tf.float32,\n",
    "        shape = [None, 256, 256, 3])\n",
    "    heatmaps_groundtruth = tf.placeholder(\n",
    "        name = 'heatmap_groundtruth',\n",
    "        dtype = tf.float32,\n",
    "        shape = [None, 64, 64, len(JOINT)])\n",
    "    train = tf.placeholder(\n",
    "        name = 'train',\n",
    "        dtype = tf.bool,\n",
    "        shape = ())\n",
    "    mask = tf.placeholder(\n",
    "        name = 'mask',\n",
    "        dtype = tf.float32,\n",
    "        shape = [len(JOINT)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size 256 * 256 * 3\n",
    "\n",
    "with tf.variable_scope('compress'):\n",
    "    with tf.variable_scope('conv_bn_relu'):\n",
    "        net = layer.conv(input = images, ksize = 7, kchannel = 64, kstride = 2) # 128 * 128 * 64\n",
    "        net = layer.bn(input = net, train = train)\n",
    "        net = layer.relu(input = net)\n",
    "\n",
    "    net = module.bottleneck(input = net, kchannel = 128, train = train, name = 'A') # 128 * 128 * 128\n",
    "    net = layer.pool(input = net) # 64 * 64 * 128\n",
    "    net = module.bottleneck(input = net, kchannel = 128, train = train, name = 'B') # 64 * 64 * 128\n",
    "    net = module.bottleneck(input = net, kchannel = 256, train = train, name = 'C') # 64 * 64 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tf_Spectrum:\n",
    "    Color = tf.constant([\n",
    "        [0, 0, 128],\n",
    "        [0, 0, 255],\n",
    "        [0, 255, 0],\n",
    "        [255, 255, 0],\n",
    "        [255, 0, 0]\n",
    "    ], dtype = tf.float32)\n",
    "\n",
    "def tf_gray2color(gray, spectrum = tf_Spectrum.Color):\n",
    "    indices = tf.floor_div(gray, 64)\n",
    "    \n",
    "    t = tf.expand_dims((gray - indices * 64) / (64), axis = -1)\n",
    "    indices = tf.cast(indices, dtype = tf.int32)\n",
    "    \n",
    "    return tf.add(\n",
    "        tf.multiply(tf.gather(spectrum, indices), 1 - t),\n",
    "        tf.multiply(tf.gather(spectrum, indices+1), t)\n",
    "    )\n",
    "\n",
    "def tf_merge(rgb, heat):\n",
    "    heat = tf.image.resize_images(\n",
    "        heat,\n",
    "        [256, 256]\n",
    "    )\n",
    "    heat = tf.reduce_max(\n",
    "        heat,\n",
    "        axis = -1\n",
    "    )\n",
    "    return tf.cast(\n",
    "        tf.add(\n",
    "            tf.multiply(\n",
    "                tf_gray2color(heat),\n",
    "                0.6\n",
    "            ),\n",
    "            tf.multiply(rgb, 0.4)\n",
    "        ),\n",
    "        dtype = tf.uint8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_stage = 8\n",
    "heatmaps = []\n",
    "if FLAGS.task == 'eval':\n",
    "    output = []\n",
    "\n",
    "for stage in range(1, last_stage+1):\n",
    "    with tf.variable_scope('hourglass_' + str(stage)):\n",
    "        prev = tf.identity(net)\n",
    "        net = module.hourglass(input = net, train = train) # 64 * 64 * 256\n",
    "\n",
    "        with tf.variable_scope('inter_hourglasses'):\n",
    "            net = module.bottleneck(input = net, train = train) # 64 * 64 * 256\n",
    "            net = layer.conv(input = net, ksize = 1, kchannel = 256) # 64 * 64 * 256\n",
    "            net = layer.bn(input = net, train = train)\n",
    "            net = layer.relu(input = net)\n",
    "\n",
    "        with tf.variable_scope('heatmap'):\n",
    "            heatmap = layer.conv(input = net, ksize = 1, kchannel = len(JOINT)) # 64 * 64 * joint\n",
    "            \n",
    "            heatmaps.append(heatmap)\n",
    "            if FLAGS.task == 'eval':\n",
    "                output.append(tf_merge(images, heatmap))\n",
    "\n",
    "        if stage != last_stage:\n",
    "            net = layer.conv(input = net, ksize = 1, kchannel = 256, name = 'inter')\\\n",
    "                + layer.conv(input = heatmap, ksize = 1, kchannel = 256, name = 'heatmap')\\\n",
    "                + prev # 64 * 64 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAGS.task == 'train' :\n",
    "    with tf.variable_scope('loss'):\n",
    "        loss = tf.losses.mean_squared_error(heatmaps_groundtruth, heatmaps[0] * mask)\n",
    "        for stage in range(1, last_stage):\n",
    "            loss = loss + tf.losses.mean_squared_error(heatmaps_groundtruth, heatmaps[stage] * mask)\n",
    "        summary_loss = tf.summary.scalar('loss', loss)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.AdamOptimizer(name = 'optimizer', learning_rate = 0.00025).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/nulledge/Workspace/pretrained/hourglass/2018-01-24 09:50:49.998469_MPIIepoch20_FLICepoch100.ckpt\n"
     ]
    }
   ],
   "source": [
    "summary_merged = tf.summary.merge_all()\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(FLAGS.path_to_log, sess.graph)\n",
    "\n",
    "reader = DataCenter(root = FLAGS.path_to_data).request(data = FLAGS.name_of_data, task = FLAGS.task, metric = FLAGS.metric)\n",
    "\n",
    "if FLAGS.load_pretrained:\n",
    "    list_of_files = glob.glob(os.path.join(FLAGS.path_to_pretrained, '*'))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    file_name = os.path.basename(latest_file).split('.ckpt')[0]\n",
    "    saver.restore(sess, os.path.join(FLAGS.path_to_pretrained, file_name + '.ckpt'))\n",
    "else:\n",
    "    file_name = 'None'\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ckpt: 2018-01-24 09:50:49.998469_MPIIepoch20_FLICepoch100:   0%|          | 0/501 [00:00<?, ?it/s]\u001b[A\n",
      "ckpt: 2018-01-24 09:50:49.998469_MPIIepoch20_FLICepoch100: 100%|██████████| 501/501 [01:21<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOINT.L_Shoulder 98.40319361277446%\n",
      "JOINT.R_Shoulder 97.0059880239521%\n",
      "JOINT.L_Elbow 95.00998003992017%\n",
      "JOINT.R_Elbow 95.00998003992017%\n",
      "JOINT.L_Wrist 86.62674650698602%\n",
      "JOINT.R_Wrist 89.42115768463074%\n",
      "JOINT.L_Hip 95.40918163672654%\n",
      "JOINT.R_Hip 93.21357285429141%\n",
      "JOINT.L_Eye 98.80239520958084%\n",
      "JOINT.R_Eye 98.80239520958084%\n",
      "JOINT.M_Nose 99.40119760479041%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.task == 'train':\n",
    "    idx = 0\n",
    "    for epoch in range(1, FLAGS.epoch + 1):\n",
    "        if FLAGS.name_of_data == 'FLIC':\n",
    "            one_epoch = int(FLIC.NUMBER_OF_DATA * FLIC.TRAIN_RATIO)\n",
    "        elif FLAGS.name_of_data == 'MPII':\n",
    "            one_epoch = int(MPII.NUMBER_OF_DATA * MPII.TRAIN_RATIO)\n",
    "        train_iter = tqdm(total = one_epoch, desc = 'epoch: ' + str(epoch) + '/' + str(FLAGS.epoch))\n",
    "        reader.reset()\n",
    "        for i in range(one_epoch):\n",
    "            train_images, train_heatmaps, train_pose, train_threshold, train_mask = reader.getBatch(8)\n",
    "            if train_images.shape[0] == 0:\n",
    "                break\n",
    "            _, result, summary = sess.run([optimizer, loss, summary_merged],\n",
    "                feed_dict = {\n",
    "                    images: train_images,\n",
    "                    heatmaps_groundtruth: train_heatmaps,\n",
    "                    train: True,\n",
    "                    mask: train_mask\n",
    "                })\n",
    "            train_iter.set_postfix(loss = result)\n",
    "            train_iter.update(train_images.shape[0])\n",
    "            writer.add_summary(summary, idx)\n",
    "            idx += 1\n",
    "        train_iter.close();\n",
    "        \n",
    "        if FLAGS.save_pretrained and epoch % 10 == 0:\n",
    "            # save_path = saver.save(sess, os.path.join(FLAGS.path_to_pretrained, str(datetime.datetime.now()) + '_MPIIepoch20_FLICepoch100.ckpt'))\n",
    "            # print('save to:', save_path)\n",
    "            print('save failed.')\n",
    "else:\n",
    "    if FLAGS.name_of_data == 'FLIC':\n",
    "        one_epoch = FLIC.NUMBER_OF_DATA - int(FLIC.NUMBER_OF_DATA * FLIC.TRAIN_RATIO)\n",
    "    elif FLAGS.name_of_data == 'MPII':\n",
    "        one_epoch = MPII.NUMBER_OF_DATA - int(MPII.NUMBER_OF_DATA * MPII.TRAIN_RATIO)\n",
    "        \n",
    "    reader.reset()\n",
    "    eval_iter = tqdm(total = one_epoch, desc = 'ckpt: ' + file_name)\n",
    "    cnt = [0] * len(JOINT)\n",
    "    for i in range(one_epoch):\n",
    "        eval_images, eval_heatmaps, eval_pose, eval_threshold, eval_mask = reader.getBatch(8)\n",
    "        if eval_images.shape[0] == 0:\n",
    "            break\n",
    "        to_cal, result = sess.run([heatmaps, output],\n",
    "            feed_dict = {\n",
    "                images: eval_images,\n",
    "                heatmaps_groundtruth: eval_heatmaps,\n",
    "                train: False})\n",
    "        eval_iter.update(eval_images.shape[0])\n",
    "        \n",
    "        for batch in range(eval_images.shape[0]):\n",
    "            for joint in JOINT:\n",
    "                if FLAGS.name_of_data == 'FLIC' and joint in FLIC.JOINT_TO_INDEX:\n",
    "                    maximum = -1.0\n",
    "                    px = -1\n",
    "                    py = -1\n",
    "                    for y in range(64):\n",
    "                        for x in range(64):\n",
    "                            if to_cal[-1][batch][y, x, joint.value] > maximum:\n",
    "                                maximum = to_cal[-1][batch][y, x, joint.value]\n",
    "                                py = y\n",
    "                                px = x\n",
    "                    dist = np.linalg.norm(\n",
    "                        np.array([py, px])\n",
    "                        - np.array(eval_pose[batch][joint.value]))\n",
    "                    if dist <= eval_threshold[batch] * FLAGS.metric_coefficient:\n",
    "                        cnt[joint.value] += 1\n",
    "                elif FLAGS.name_of_data == 'MPII' and joint in MPII.JOINT_TO_INDEX:\n",
    "                    pass\n",
    "            imageio.imwrite('img/result' + str(i) + '_' + str(batch) + '_' + str(cnt) + '_' + str(len(FLIC.JOINT_TO_INDEX)) + '.png', result[-1][batch])\n",
    "    for joint in JOINT:\n",
    "        if joint not in FLIC.JOINT_TO_INDEX:\n",
    "            continue\n",
    "        print(joint, cnt[joint.value] / one_epoch * 100, end = '%\\n')\n",
    "                \n",
    "            \n",
    "    eval_iter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reader.resetBatch()\n",
    "_, heat, _, _ = reader.getBatch(1)\n",
    "heat = heat[0]\n",
    "maximum = -1\n",
    "for y in range(64):\n",
    "    for x in range(64):\n",
    "        heat[y, x, 0] = max(heat[y, x, :])\n",
    "        if heat[y, x, 0] > maximum:\n",
    "            maximum = heat[y, x, 0]\n",
    "imageio.imwrite('img/heat.jpg', heat[:, :, 0])\n",
    "print(maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-36",
   "language": "python",
   "name": "th-36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
